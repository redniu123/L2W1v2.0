# L2W1 v5.0 çœŸå®žæ•°æ®è¿è¡ŒæŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨ä½¿ç”¨çœŸå®žæ•°æ®å®Œæ•´è¿è¡Œ L2W1 v5.0 é¡¹ç›®ã€‚

---

## ðŸ“‹ ç›®å½•

1. [æ¨¡åž‹ä¸‹è½½è¯´æ˜Ž](#æ¨¡åž‹ä¸‹è½½è¯´æ˜Ž)
2. [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
3. [å®Œæ•´è¿è¡Œæµç¨‹](#å®Œæ•´è¿è¡Œæµç¨‹)
4. [åˆ†æ­¥éª¤è¿è¡Œ](#åˆ†æ­¥éª¤è¿è¡Œ)
5. [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ðŸ“¦ æ¨¡åž‹ä¸‹è½½è¯´æ˜Ž

### è‡ªåŠ¨ä¸‹è½½çš„æ¨¡åž‹

ä»¥ä¸‹æ¨¡åž‹ä¼šåœ¨é¦–æ¬¡ä½¿ç”¨æ—¶**è‡ªåŠ¨ä»Ž HuggingFace ä¸‹è½½**ï¼š

| æ¨¡åž‹ | æ¥æº | å¤§å° | ä¸‹è½½ä½ç½® |
|------|------|------|----------|
| **Agent B (Qwen2.5-VL-3B)** | HuggingFace | ~6GB | `~/.cache/huggingface/hub/` |
| **Router è¯­è¨€æ¨¡åž‹ (Qwen2.5-0.5B)** | HuggingFace | ~1GB | `~/.cache/huggingface/hub/` |

**è¯´æ˜Ž**ï¼š
- ä½¿ç”¨ `transformers` åº“çš„ `from_pretrained()` ä¼šè‡ªåŠ¨ä¸‹è½½
- é¦–æ¬¡è¿è¡Œæ—¶ä¼šæ˜¾ç¤ºä¸‹è½½è¿›åº¦
- ä¸‹è½½åŽä¼šè‡ªåŠ¨ç¼“å­˜ï¼ŒåŽç»­è¿è¡Œæ— éœ€é‡æ–°ä¸‹è½½
- å¦‚æžœç½‘ç»œè¾ƒæ…¢ï¼Œå¯ä»¥é¢„å…ˆä¸‹è½½ï¼ˆè§ä¸‹æ–¹"æ‰‹åŠ¨ä¸‹è½½"ï¼‰

### éœ€è¦æ‰‹åŠ¨ä¸‹è½½çš„æ¨¡åž‹

| æ¨¡åž‹ | æ¥æº | å¤§å° | ä¸‹è½½ä½ç½® |
|------|------|------|----------|
| **Agent A (PP-OCRv5-Rec)** | PaddleOCR | ~10MB | `models/agent_a_ppocr/` |

**ä¸‹è½½æ–¹æ³•**ï¼š

```bash
# æ–¹æ³• 1: ä½¿ç”¨ PaddleOCR å®˜æ–¹å·¥å…·
pip install paddleocr
python -c "
from paddleocr import PaddleOCR
ocr = PaddleOCR(use_angle_cls=False, lang='ch')
# æ¨¡åž‹ä¼šè‡ªåŠ¨ä¸‹è½½åˆ° ~/.paddleocr/whl/rec/ch/
"

# æ–¹æ³• 2: æ‰‹åŠ¨ä¸‹è½½ï¼ˆæŽ¨èï¼‰
mkdir -p models/agent_a_ppocr
cd models/agent_a_ppocr

# ä¸‹è½½ PP-OCRv5 è¯†åˆ«æ¨¡åž‹
wget https://paddleocr.bj.bcebos.com/PP-OCRv5/chinese/ch_PP-OCRv5_rec_infer.tar
tar -xf ch_PP-OCRv5_rec_infer.tar
mv inference/* .
rm -rf inference ch_PP-OCRv5_rec_infer.tar

# éªŒè¯æ–‡ä»¶
ls -lh
# åº”è¯¥çœ‹åˆ°: inference.pdmodel, inference.pdiparams ç­‰æ–‡ä»¶
```

---

## ðŸ“ æ•°æ®å‡†å¤‡

### æ•°æ®æ ¼å¼è¦æ±‚

L2W1 éœ€è¦ä»¥ä¸‹æ ¼å¼çš„æ•°æ®ï¼š

```
data/
â”œâ”€â”€ raw/                    # åŽŸå§‹æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ images/            # å›¾åƒæ–‡ä»¶ç›®å½•
â”‚   â”‚   â”œâ”€â”€ line_001.jpg
â”‚   â”‚   â”œâ”€â”€ line_002.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ labels.txt         # æ ‡æ³¨æ–‡ä»¶ï¼ˆæ ¼å¼ï¼šimage_path\tground_truthï¼‰
â””â”€â”€ test/                  # æµ‹è¯•æ•°æ®ï¼ˆå¯é€‰ï¼‰
    â”œâ”€â”€ images/
    â””â”€â”€ labels.txt
```

### labels.txt æ ¼å¼

æ¯è¡Œæ ¼å¼ï¼š`å›¾åƒè·¯å¾„\tçœŸå€¼æ–‡æœ¬`

```txt
images/line_001.jpg	ä¸­å›½ç§‘å­¦é™¢è®¡ç®—æŠ€æœ¯ç ”ç©¶æ‰€
images/line_002.jpg	åœ¨æ—¶é—´çš„æœªå°¾ï¼Œæˆ‘ä»¬ç›¸é‡
images/line_003.jpg	æ‰‹å†™æ–‡æœ¬è¯†åˆ«ç³»ç»Ÿ
```

### å‡†å¤‡æµ‹è¯•æ•°æ®

```bash
# 1. åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/raw/images
mkdir -p data/test/images

# 2. å°†å›¾åƒæ–‡ä»¶æ”¾å…¥ images/ ç›®å½•
# cp your_images/*.jpg data/raw/images/

# 3. åˆ›å»ºæ ‡æ³¨æ–‡ä»¶
cat > data/raw/labels.txt << 'EOF'
images/line_001.jpg	çœŸå€¼æ–‡æœ¬1
images/line_002.jpg	çœŸå€¼æ–‡æœ¬2
EOF

# 4. éªŒè¯æ•°æ®
head -n 5 data/raw/labels.txt
ls data/raw/images/ | head -n 5
```

---

## ðŸš€ å®Œæ•´è¿è¡Œæµç¨‹

### æ–¹å¼ 1: ç«¯åˆ°ç«¯ Pipelineï¼ˆæŽ¨èï¼‰

```bash
# æ¿€æ´»çŽ¯å¢ƒ
conda activate l2w1v2

# åˆ›å»ºè¿è¡Œè„šæœ¬
cat > run_pipeline.py << 'EOF'
#!/usr/bin/env python3
"""L2W1 ç«¯åˆ°ç«¯è¿è¡Œè„šæœ¬"""
import sys
from pathlib import Path
from modules import L2W1Pipeline, PipelineConfig

# é…ç½®
config = PipelineConfig(
    # Agent A é…ç½®
    agent_a_model_dir="./models/agent_a_ppocr",
    
    # Agent B é…ç½®ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
    agent_b_model_path="Qwen/Qwen2.5-VL-3B-Instruct",
    agent_b_use_4bit=True,
    
    # Router é…ç½®
    entropy_threshold_low=2.0,
    entropy_threshold_high=4.0,
    
    # å…¶ä»–
    verbose=True
)

# åˆ›å»º Pipeline
print("æ­£åœ¨åˆå§‹åŒ– L2W1 Pipeline...")
pipeline = L2W1Pipeline(config)
print("Pipeline åˆå§‹åŒ–å®Œæˆ!\n")

# å¤„ç†å•å¼ å›¾åƒ
image_path = sys.argv[1] if len(sys.argv) > 1 else "data/raw/images/line_001.jpg"

if not Path(image_path).exists():
    print(f"é”™è¯¯: å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
    sys.exit(1)

print(f"å¤„ç†å›¾åƒ: {image_path}")
result = pipeline.process(image_path)

# è¾“å‡ºç»“æžœ
print("\n" + "="*60)
print("L2W1 æŽ¨ç†ç»“æžœ")
print("="*60)
print(f"Agent A è¯†åˆ«: {result.agent_a_text}")
print(f"æ˜¯å¦å›°éš¾æ ·æœ¬: {result.is_hard}")
if result.is_hard:
    print(f"é£Žé™©ç­‰çº§: {result.risk_level}")
    print(f"å­˜ç–‘å­—ç¬¦ç´¢å¼•: {result.suspicious_index} (å­—ç¬¦: '{result.suspicious_char}')")
    print(f"Agent B ä¿®æ­£: {result.agent_b_text}")
print(f"æœ€ç»ˆè¾“å‡º: {result.final_text}")
print("="*60)
EOF

# è¿è¡Œ
python run_pipeline.py data/raw/images/line_001.jpg
```

### æ–¹å¼ 2: æ‰¹é‡å¤„ç†

```bash
cat > run_batch.py << 'EOF'
#!/usr/bin/env python3
"""æ‰¹é‡å¤„ç†è„šæœ¬"""
import json
from pathlib import Path
from modules import L2W1Pipeline, PipelineConfig

# é…ç½®
config = PipelineConfig(
    agent_a_model_dir="./models/agent_a_ppocr",
    agent_b_model_path="Qwen/Qwen2.5-VL-3B-Instruct",
    agent_b_use_4bit=True,
    verbose=False
)

# åˆ›å»º Pipeline
pipeline = L2W1Pipeline(config)

# è¯»å–æ ‡æ³¨æ–‡ä»¶
labels_file = Path("data/raw/labels.txt")
results = []

with open(labels_file, 'r', encoding='utf-8') as f:
    for line in f:
        line = line.strip()
        if not line or '\t' not in line:
            continue
        
        image_path, gt_text = line.split('\t', 1)
        full_path = Path("data/raw") / image_path
        
        if not full_path.exists():
            print(f"è·³è¿‡: {full_path} ä¸å­˜åœ¨")
            continue
        
        print(f"å¤„ç†: {image_path}")
        result = pipeline.process(str(full_path))
        
        results.append({
            'image': image_path,
            'agent_a_text': result.agent_a_text,
            'final_text': result.final_text,
            'gt_text': gt_text,
            'is_hard': result.is_hard,
            'routed_to_agent_b': result.routed_to_agent_b
        })

# ä¿å­˜ç»“æžœ
output_file = Path("data/test/inference_results.jsonl")
with open(output_file, 'w', encoding='utf-8') as f:
    for r in results:
        f.write(json.dumps(r, ensure_ascii=False) + '\n')

print(f"\nå¤„ç†å®Œæˆ! ç»“æžœä¿å­˜åˆ°: {output_file}")
print(f"å…±å¤„ç† {len(results)} ä¸ªæ ·æœ¬")
EOF

python run_batch.py
```

---

## ðŸ“ åˆ†æ­¥éª¤è¿è¡Œ

### æ­¥éª¤ 1: ç”Ÿæˆ SFT æ•°æ®é›†

```bash
# è¿è¡Œæ•°æ®ç®¡é“
python scripts/data_pipeline.py \
    --data_dir ./data/raw \
    --output_path ./data/sft/agent_b_train.jsonl \
    --batch_size 32 \
    --max_cer 0.3

# æ£€æŸ¥è¾“å‡º
head -n 3 ./data/sft/agent_b_train.jsonl
wc -l ./data/sft/agent_b_train.jsonl
```

**é¢„æœŸè¾“å‡º**ï¼š
- `data/sft/agent_b_train.jsonl`: è®­ç»ƒæ•°æ®é›†
- æŽ§åˆ¶å°æ˜¾ç¤ºå¤„ç†è¿›åº¦å’Œç»Ÿè®¡ä¿¡æ¯

### æ­¥éª¤ 2: è®­ç»ƒ Agent Bï¼ˆå¯é€‰ï¼‰

```bash
# è®­ç»ƒ Agent B
python scripts/train_agent_b.py \
    --data_path ./data/sft/agent_b_train.jsonl \
    --output_dir ./models/agent_b_vlm/lora_checkpoints \
    --model_path Qwen/Qwen2.5-VL-3B-Instruct \
    --use_4bit \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 8 \
    --num_train_epochs 3 \
    --save_steps 500

# æ£€æŸ¥æ£€æŸ¥ç‚¹
ls -lh ./models/agent_b_vlm/lora_checkpoints/
```

### æ­¥éª¤ 3: è¿è¡ŒæŽ¨ç†

```bash
# ä½¿ç”¨ Pipeline å¤„ç†å›¾åƒ
python run_pipeline.py data/raw/images/line_001.jpg

# æˆ–æ‰¹é‡å¤„ç†
python run_batch.py
```

### æ­¥éª¤ 4: è¯„ä¼°ç»“æžœ

```bash
# è¿è¡Œè¯„ä¼°
python scripts/evaluate.py \
    --predictions ./data/test/inference_results.jsonl \
    --output_dir ./data/test \
    --save_report

# æŸ¥çœ‹è¯„ä¼°æŠ¥å‘Š
cat ./data/test/evaluation_report.json
```

### æ­¥éª¤ 5: å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰

```bash
# ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
python scripts/visualize_results.py \
    --eval_report ./data/test/evaluation_report.json \
    --output_dir ./outputs/figures
```

---

## ðŸ”§ æ¨¡åž‹ä¸‹è½½è¯¦ç»†è¯´æ˜Ž

### Agent B æ¨¡åž‹ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼‰

**é¦–æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½**ï¼Œæ‚¨ä¹Ÿå¯ä»¥é¢„å…ˆä¸‹è½½ï¼š

```bash
# é¢„å…ˆä¸‹è½½ Qwen2.5-VL-3B
python -c "
from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor
print('æ­£åœ¨ä¸‹è½½ Qwen2.5-VL-3B...')
model = Qwen2_5_VLForConditionalGeneration.from_pretrained(
    'Qwen/Qwen2.5-VL-3B-Instruct',
    trust_remote_code=True
)
processor = AutoProcessor.from_pretrained(
    'Qwen/Qwen2.5-VL-3B-Instruct',
    trust_remote_code=True
)
print('ä¸‹è½½å®Œæˆ!')
"

# æ¨¡åž‹ä¼šä¸‹è½½åˆ°: ~/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/
```

### Agent A æ¨¡åž‹ï¼ˆæ‰‹åŠ¨ä¸‹è½½ï¼‰

```bash
# åˆ›å»ºæ¨¡åž‹ç›®å½•
mkdir -p models/agent_a_ppocr
cd models/agent_a_ppocr

# ä¸‹è½½ PP-OCRv5 ä¸­æ–‡è¯†åˆ«æ¨¡åž‹
wget https://paddleocr.bj.bcebos.com/PP-OCRv5/chinese/ch_PP-OCRv5_rec_infer.tar

# è§£åŽ‹
tar -xf ch_PP-OCRv5_rec_infer.tar

# æ•´ç†æ–‡ä»¶
mv inference/* .
rmdir inference
rm ch_PP-OCRv5_rec_infer.tar

# éªŒè¯
ls -lh
# åº”è¯¥çœ‹åˆ°:
# - inference.pdmodel
# - inference.pdiparams
# - inference.yml (å¯é€‰)

cd ../..
```

### Router è¯­è¨€æ¨¡åž‹ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼Œå¯é€‰ï¼‰

Router çš„è¯­è¨€æ¨¡åž‹ä¼šåœ¨é¦–æ¬¡è®¡ç®—è¯­ä¹‰ PPL æ—¶è‡ªåŠ¨ä¸‹è½½ã€‚å¦‚æžœéœ€è¦é¢„å…ˆä¸‹è½½ï¼š

```bash
python -c "
from transformers import AutoModelForCausalLM, AutoTokenizer
print('æ­£åœ¨ä¸‹è½½ Qwen2.5-0.5B...')
model = AutoModelForCausalLM.from_pretrained('Qwen/Qwen2.5-0.5B-Instruct')
tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-0.5B-Instruct')
print('ä¸‹è½½å®Œæˆ!')
"
```

---

## âš™ï¸ é…ç½®è¯´æ˜Ž

### Pipeline é…ç½®

```python
config = PipelineConfig(
    # Agent A é…ç½®
    agent_a_model_dir="./models/agent_a_ppocr",  # PP-OCRv5 æ¨¡åž‹è·¯å¾„
    
    # Agent B é…ç½®
    agent_b_model_path="Qwen/Qwen2.5-VL-3B-Instruct",  # HuggingFace æ¨¡åž‹åæˆ–æœ¬åœ°è·¯å¾„
    agent_b_use_4bit=True,  # ä½¿ç”¨ 4-bit é‡åŒ–ï¼ˆèŠ‚çœæ˜¾å­˜ï¼‰
    
    # Router é…ç½®
    entropy_threshold_low=2.0,   # è§†è§‰ç†µä½Žé˜ˆå€¼
    entropy_threshold_high=4.0,  # è§†è§‰ç†µé«˜é˜ˆå€¼
    ppl_threshold_low=50.0,      # è¯­ä¹‰ PPL ä½Žé˜ˆå€¼
    ppl_threshold_high=200.0,    # è¯­ä¹‰ PPL é«˜é˜ˆå€¼
    
    # å…¶ä»–
    verbose=True  # æ‰“å°è¯¦ç»†æ—¥å¿—
)
```

### ä½¿ç”¨æœ¬åœ°æ¨¡åž‹

å¦‚æžœå·²ç»ä¸‹è½½äº†æ¨¡åž‹åˆ°æœ¬åœ°ï¼š

```python
config = PipelineConfig(
    agent_b_model_path="./models/qwen2.5-vl-3b",  # æœ¬åœ°è·¯å¾„
    # ...
)
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: Agent B æ¨¡åž‹ä¸‹è½½å¾ˆæ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨é•œåƒæºï¼ˆå¦‚æžœåœ¨ä¸­å›½ï¼‰ï¼š
   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```
2. é¢„å…ˆä¸‹è½½ï¼ˆè§ä¸Šæ–¹"æ¨¡åž‹ä¸‹è½½è¯¦ç»†è¯´æ˜Ž"ï¼‰
3. ä½¿ç”¨ä»£ç†

### Q2: Agent A æ¨¡åž‹æ‰¾ä¸åˆ°

**é”™è¯¯**: `not find model file path`

**è§£å†³**:
```bash
# æ£€æŸ¥æ¨¡åž‹è·¯å¾„
ls -lh models/agent_a_ppocr/

# ç¡®ä¿æœ‰ä»¥ä¸‹æ–‡ä»¶:
# - inference.pdmodel
# - inference.pdiparams

# å¦‚æžœç¼ºå°‘ï¼Œé‡æ–°ä¸‹è½½ï¼ˆè§ä¸Šæ–¹"Agent A æ¨¡åž‹ä¸‹è½½"ï¼‰
```

### Q3: æ˜¾å­˜ä¸è¶³

**é”™è¯¯**: CUDA OOM

**è§£å†³**:
```python
# ç¡®ä¿ä½¿ç”¨ 4-bit é‡åŒ–
config = PipelineConfig(
    agent_b_use_4bit=True,  # å¿…é¡»ä¸º True
    # ...
)
```

### Q4: ç½‘ç»œé—®é¢˜å¯¼è‡´æ¨¡åž‹ä¸‹è½½å¤±è´¥

**è§£å†³**:
1. æ‰‹åŠ¨ä¸‹è½½æ¨¡åž‹åˆ°æœ¬åœ°
2. ä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼š
   ```python
   config.agent_b_model_path = "./models/qwen2.5-vl-3b"
   ```

---

## ðŸ“Š å¿«é€ŸéªŒè¯

è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯æ‰€æœ‰ç»„ä»¶ï¼š

```bash
# 1. æ£€æŸ¥ Agent A æ¨¡åž‹
ls -lh models/agent_a_ppocr/inference.*

# 2. æµ‹è¯• Pipelineï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½ Agent Bï¼‰
python -c "
from modules import L2W1Pipeline, PipelineConfig
config = PipelineConfig(agent_a_model_dir='./models/agent_a_ppocr')
pipeline = L2W1Pipeline(config)
print('âœ“ Pipeline åˆå§‹åŒ–æˆåŠŸ')
"

# 3. æ£€æŸ¥æ•°æ®
head -n 3 data/raw/labels.txt
ls data/raw/images/ | head -n 3
```

---

## ðŸŽ¯ å®Œæ•´ç¤ºä¾‹

```bash
# 1. å‡†å¤‡æ•°æ®
mkdir -p data/raw/images
# å°†å›¾åƒæ”¾å…¥ data/raw/images/
# åˆ›å»º data/raw/labels.txt

# 2. ä¸‹è½½ Agent A æ¨¡åž‹
mkdir -p models/agent_a_ppocr
cd models/agent_a_ppocr
wget https://paddleocr.bj.bcebos.com/PP-OCRv5/chinese/ch_PP-OCRv5_rec_infer.tar
tar -xf ch_PP-OCRv5_rec_infer.tar && mv inference/* . && rm -rf inference *.tar
cd ../..

# 3. è¿è¡Œ Pipelineï¼ˆAgent B ä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
python run_pipeline.py data/raw/images/line_001.jpg

# 4. æ‰¹é‡å¤„ç†
python run_batch.py

# 5. è¯„ä¼°
python scripts/evaluate.py --predictions ./data/test/inference_results.jsonl
```

---

**å‡†å¤‡å¥½æ•°æ®åŽï¼ŒæŒ‰ç…§ä¸Šè¿°æ­¥éª¤è¿è¡Œå³å¯ï¼** ðŸš€

