#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
L2W1 è¾¹ç•Œå¤±è´¥æ·±åº¦åˆ†æè„šæœ¬

å¯¹ PP-OCRv5 åœ¨ HWDB æ•°æ®é›†ä¸Šçš„"è¾¹ç•Œæ„ŸçŸ¥åå¡Œ"ç°è±¡è¿›è¡Œé‡åŒ–åˆ†æã€‚

åˆ†æç»´åº¦:
1. é”™è¯¯ä½ç½®å½’ä¸€åŒ–åˆ†å¸ƒ (0=å·¦è¾¹ç•Œ, 1=å³è¾¹ç•Œ)
2. é”™è¯¯ç±»å‹åˆ†ç±» (Deletion/Substitution/Insertion)
3. åˆ†æ®µ CER å¯¹æ¯” (Boundary_Left / Boundary_Right / Mid_Section)
4. è®ºæ–‡çº§ç»Ÿè®¡æŒ‡æ ‡

è¾“å‡º:
- results/boundary_analysis_report.json: è¯¦ç»†åˆ†ææŠ¥å‘Š
- results/error_heatmap_data.csv: çƒ­å›¾æ•°æ®
- results/boundary_analysis.png: å¯è§†åŒ–å›¾è¡¨ (å¦‚æœ matplotlib å¯ç”¨)

Usage:
    python scripts/analyze_boundary_failures.py
    python scripts/analyze_boundary_failures.py --input results/baseline_results.jsonl
"""

import json
import csv
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, field, asdict
from collections import defaultdict
import sys

# ç¬¬ä¸‰æ–¹åº“
try:
    import Levenshtein
    from Levenshtein import editops

    HAS_LEVENSHTEIN = True
except ImportError:
    HAS_LEVENSHTEIN = False
    print("[WARNING] Levenshtein åº“æœªå®‰è£…ï¼Œä½¿ç”¨å†…ç½®å®ç°")

try:
    import numpy as np

    HAS_NUMPY = True
except ImportError:
    HAS_NUMPY = False
    print("[WARNING] numpy æœªå®‰è£…ï¼Œéƒ¨åˆ†ç»Ÿè®¡åŠŸèƒ½å—é™")

try:
    import matplotlib.pyplot as plt
    import matplotlib

    matplotlib.use("Agg")  # éäº¤äº’å¼åç«¯
    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False
    print("[WARNING] matplotlib æœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")


# ==================== æ•°æ®ç»“æ„å®šä¹‰ ====================


@dataclass
class ErrorInstance:
    """å•ä¸ªé”™è¯¯å®ä¾‹"""

    sample_id: str
    error_type: str  # "delete", "insert", "replace"
    position: int  # åœ¨ GT æ–‡æœ¬ä¸­çš„ä½ç½®
    normalized_position: float  # å½’ä¸€åŒ–ä½ç½® [0, 1]
    gt_char: str  # GT å­—ç¬¦
    pred_char: str  # é¢„æµ‹å­—ç¬¦ (æ›¿æ¢/æ’å…¥) æˆ–ç©º (åˆ é™¤)
    gt_length: int  # GT æ–‡æœ¬æ€»é•¿åº¦


@dataclass
class SegmentStats:
    """åˆ†æ®µç»Ÿè®¡"""

    total_chars: int = 0
    error_chars: int = 0
    delete_count: int = 0
    insert_count: int = 0
    replace_count: int = 0

    @property
    def cer(self) -> float:
        if self.total_chars == 0:
            return 0.0
        return self.error_chars / self.total_chars


@dataclass
class AnalysisReport:
    """åˆ†ææŠ¥å‘Š"""

    # åŸºç¡€ç»Ÿè®¡
    total_samples: int = 0
    valid_samples: int = 0
    skipped_samples: int = 0

    # æ•´ä½“æŒ‡æ ‡
    overall_cer: float = 0.0
    overall_avg_confidence: float = 0.0

    # åˆ†æ®µ CER
    boundary_left_stats: SegmentStats = field(default_factory=SegmentStats)
    boundary_right_stats: SegmentStats = field(default_factory=SegmentStats)
    mid_section_stats: SegmentStats = field(default_factory=SegmentStats)

    # è¾¹ç•Œåˆ†æ
    boundary_cer: float = 0.0
    mid_cer: float = 0.0
    boundary_to_mid_ratio: float = 0.0

    # ä½ç½®åˆ†å¸ƒ
    edge_10_percent_error_ratio: float = 0.0  # è¾¹ç¼˜ 10% åŒºåŸŸçš„é”™è¯¯å æ¯”
    edge_20_percent_error_ratio: float = 0.0  # è¾¹ç¼˜ 20% åŒºåŸŸçš„é”™è¯¯å æ¯”

    # é”™è¯¯ç±»å‹åˆ†å¸ƒ
    total_errors: int = 0
    delete_errors: int = 0
    insert_errors: int = 0
    replace_errors: int = 0

    # è®ºæ–‡çº§ç»“è®º
    hypothesis_confirmed: bool = False  # CER_boundary > 3 Ã— CER_mid
    boundary_crisis_severity: str = ""  # ä¸¥é‡ç¨‹åº¦è¯„ä¼°


# ==================== æ ¸å¿ƒåˆ†æé€»è¾‘ ====================


def simple_editops(s1: str, s2: str) -> List[Tuple[str, int, int]]:
    """
    ç®€å•çš„ edit operations å®ç° (å½“ Levenshtein ä¸å¯ç”¨æ—¶)
    è¿”å›: [(operation, pos_s1, pos_s2), ...]
    """
    m, n = len(s1), len(s2)

    # åŠ¨æ€è§„åˆ’è¡¨
    dp = [[0] * (n + 1) for _ in range(m + 1)]

    for i in range(m + 1):
        dp[i][0] = i
    for j in range(n + 1):
        dp[0][j] = j

    for i in range(1, m + 1):
        for j in range(1, n + 1):
            if s1[i - 1] == s2[j - 1]:
                dp[i][j] = dp[i - 1][j - 1]
            else:
                dp[i][j] = min(
                    dp[i - 1][j] + 1,  # delete
                    dp[i][j - 1] + 1,  # insert
                    dp[i - 1][j - 1] + 1,  # replace
                )

    # å›æº¯è·å–æ“ä½œåºåˆ—
    ops = []
    i, j = m, n
    while i > 0 or j > 0:
        if i > 0 and j > 0 and s1[i - 1] == s2[j - 1]:
            i -= 1
            j -= 1
        elif i > 0 and j > 0 and dp[i][j] == dp[i - 1][j - 1] + 1:
            ops.append(("replace", i - 1, j - 1))
            i -= 1
            j -= 1
        elif i > 0 and dp[i][j] == dp[i - 1][j] + 1:
            ops.append(("delete", i - 1, j))
            i -= 1
        elif j > 0 and dp[i][j] == dp[i][j - 1] + 1:
            ops.append(("insert", i, j - 1))
            j -= 1
        else:
            break

    return list(reversed(ops))


def get_editops(gt_text: str, pred_text: str) -> List[Tuple[str, int, int]]:
    """è·å–ç¼–è¾‘æ“ä½œåˆ—è¡¨"""
    if HAS_LEVENSHTEIN:
        return list(editops(gt_text, pred_text))
    else:
        return simple_editops(gt_text, pred_text)


def analyze_single_sample(
    sample: Dict, boundary_window: int = 2
) -> Tuple[List[ErrorInstance], Dict]:
    """
    åˆ†æå•ä¸ªæ ·æœ¬çš„é”™è¯¯åˆ†å¸ƒ

    Args:
        sample: æ ·æœ¬æ•°æ® (åŒ…å« gt_text, pred_text, char_confidences ç­‰)
        boundary_window: è¾¹ç•Œçª—å£å¤§å° (é¦–å°¾å„å¤šå°‘ä¸ªå­—ç¬¦)

    Returns:
        Tuple[é”™è¯¯å®ä¾‹åˆ—è¡¨, åˆ†æ®µç»Ÿè®¡å­—å…¸]
    """
    sample_id = sample.get("id", "unknown")
    gt_text = sample.get("gt_text", "")
    pred_text = sample.get("pred_text", "")

    # è¾¹ç•Œæ¡ä»¶æ£€æŸ¥
    if len(gt_text) == 0:
        return [], {}

    # è·å–ç¼–è¾‘æ“ä½œ
    ops = get_editops(gt_text, pred_text)

    errors = []
    gt_len = len(gt_text)

    for op_type, gt_pos, pred_pos in ops:
        # å½’ä¸€åŒ–ä½ç½®è®¡ç®—
        if gt_len > 1:
            normalized_pos = gt_pos / (gt_len - 1) if gt_pos < gt_len else 1.0
        else:
            normalized_pos = 0.5  # å•å­—ç¬¦æƒ…å†µ

        # è·å–ç›¸å…³å­—ç¬¦
        gt_char = gt_text[gt_pos] if gt_pos < len(gt_text) else ""
        pred_char = pred_text[pred_pos] if pred_pos < len(pred_text) else ""

        error = ErrorInstance(
            sample_id=sample_id,
            error_type=op_type,
            position=gt_pos,
            normalized_position=normalized_pos,
            gt_char=gt_char,
            pred_char=pred_char,
            gt_length=gt_len,
        )
        errors.append(error)

    # åˆ†æ®µç»Ÿè®¡
    segment_stats = {
        "left": SegmentStats(total_chars=min(boundary_window, gt_len)),
        "right": SegmentStats(
            total_chars=min(boundary_window, max(0, gt_len - boundary_window))
        ),
        "mid": SegmentStats(total_chars=max(0, gt_len - 2 * boundary_window)),
    }

    # æ ¹æ®ä½ç½®åˆ†é…é”™è¯¯
    for error in errors:
        pos = error.position

        # ç¡®å®šæ‰€å±åˆ†æ®µ
        if pos < boundary_window:
            segment = "left"
        elif pos >= gt_len - boundary_window:
            segment = "right"
        else:
            segment = "mid"

        # æ›´æ–°ç»Ÿè®¡
        segment_stats[segment].error_chars += 1

        if error.error_type == "delete":
            segment_stats[segment].delete_count += 1
        elif error.error_type == "insert":
            segment_stats[segment].insert_count += 1
        elif error.error_type == "replace":
            segment_stats[segment].replace_count += 1

    return errors, segment_stats


def load_baseline_results(input_path: Path) -> List[Dict]:
    """åŠ è½½ baseline ç»“æœ"""
    if not input_path.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")

    samples = []
    with open(input_path, "r", encoding="utf-8") as f:
        for line_num, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue

            try:
                sample = json.loads(line)
                samples.append(sample)
            except json.JSONDecodeError as e:
                print(f"[WARNING] ç¬¬ {line_num} è¡Œ JSON è§£æå¤±è´¥: {e}")

    print(f"[INFO] åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
    return samples


def run_analysis(
    samples: List[Dict], boundary_window: int = 2
) -> Tuple[AnalysisReport, List[ErrorInstance]]:
    """
    æ‰§è¡Œå®Œæ•´åˆ†æ

    Args:
        samples: æ ·æœ¬åˆ—è¡¨
        boundary_window: è¾¹ç•Œçª—å£å¤§å°

    Returns:
        Tuple[åˆ†ææŠ¥å‘Š, æ‰€æœ‰é”™è¯¯å®ä¾‹]
    """
    report = AnalysisReport()
    report.total_samples = len(samples)

    all_errors: List[ErrorInstance] = []

    # èšåˆåˆ†æ®µç»Ÿè®¡
    agg_left = SegmentStats()
    agg_right = SegmentStats()
    agg_mid = SegmentStats()

    total_cer = 0.0
    total_confidence = 0.0
    valid_count = 0

    for sample in samples:
        gt_text = sample.get("gt_text", "")
        pred_text = sample.get("pred_text", "")

        # è·³è¿‡æ— æ•ˆæ ·æœ¬
        if len(gt_text) < 3:  # å¤ªçŸ­æ— æ³•åˆ†æ®µ
            report.skipped_samples += 1
            continue

        # åˆ†æå•ä¸ªæ ·æœ¬
        errors, segment_stats = analyze_single_sample(sample, boundary_window)
        all_errors.extend(errors)

        # èšåˆç»Ÿè®¡
        if "left" in segment_stats:
            agg_left.total_chars += segment_stats["left"].total_chars
            agg_left.error_chars += segment_stats["left"].error_chars
            agg_left.delete_count += segment_stats["left"].delete_count
            agg_left.insert_count += segment_stats["left"].insert_count
            agg_left.replace_count += segment_stats["left"].replace_count

        if "right" in segment_stats:
            agg_right.total_chars += segment_stats["right"].total_chars
            agg_right.error_chars += segment_stats["right"].error_chars
            agg_right.delete_count += segment_stats["right"].delete_count
            agg_right.insert_count += segment_stats["right"].insert_count
            agg_right.replace_count += segment_stats["right"].replace_count

        if "mid" in segment_stats:
            agg_mid.total_chars += segment_stats["mid"].total_chars
            agg_mid.error_chars += segment_stats["mid"].error_chars
            agg_mid.delete_count += segment_stats["mid"].delete_count
            agg_mid.insert_count += segment_stats["mid"].insert_count
            agg_mid.replace_count += segment_stats["mid"].replace_count

        # ç´¯è®¡æŒ‡æ ‡
        total_cer += sample.get("cer", 0.0)
        total_confidence += sample.get("avg_confidence", 0.0)
        valid_count += 1

    report.valid_samples = valid_count

    # è®¡ç®—æ•´ä½“æŒ‡æ ‡
    if valid_count > 0:
        report.overall_cer = total_cer / valid_count
        report.overall_avg_confidence = total_confidence / valid_count

    # åˆ†æ®µç»Ÿè®¡
    report.boundary_left_stats = agg_left
    report.boundary_right_stats = agg_right
    report.mid_section_stats = agg_mid

    # è®¡ç®—åˆ†æ®µ CER
    boundary_chars = agg_left.total_chars + agg_right.total_chars
    boundary_errors = agg_left.error_chars + agg_right.error_chars

    if boundary_chars > 0:
        report.boundary_cer = boundary_errors / boundary_chars
    if agg_mid.total_chars > 0:
        report.mid_cer = agg_mid.error_chars / agg_mid.total_chars

    # è¾¹ç•Œä¸ä¸­é—´çš„æ¯”å€¼
    if report.mid_cer > 0:
        report.boundary_to_mid_ratio = report.boundary_cer / report.mid_cer
    else:
        report.boundary_to_mid_ratio = float("inf") if report.boundary_cer > 0 else 0.0

    # é”™è¯¯ç±»å‹ç»Ÿè®¡
    report.total_errors = len(all_errors)
    report.delete_errors = sum(1 for e in all_errors if e.error_type == "delete")
    report.insert_errors = sum(1 for e in all_errors if e.error_type == "insert")
    report.replace_errors = sum(1 for e in all_errors if e.error_type == "replace")

    # ä½ç½®åˆ†å¸ƒåˆ†æ
    if all_errors:
        edge_10_count = sum(
            1
            for e in all_errors
            if e.normalized_position <= 0.1 or e.normalized_position >= 0.9
        )
        edge_20_count = sum(
            1
            for e in all_errors
            if e.normalized_position <= 0.2 or e.normalized_position >= 0.8
        )

        report.edge_10_percent_error_ratio = edge_10_count / len(all_errors)
        report.edge_20_percent_error_ratio = edge_20_count / len(all_errors)

    # éªŒè¯å‡è®¾: CER_boundary > 3 Ã— CER_mid
    report.hypothesis_confirmed = report.boundary_cer > 3 * report.mid_cer

    # è¯„ä¼°ä¸¥é‡ç¨‹åº¦
    if report.boundary_to_mid_ratio >= 5:
        report.boundary_crisis_severity = "CRITICAL"
    elif report.boundary_to_mid_ratio >= 3:
        report.boundary_crisis_severity = "SEVERE"
    elif report.boundary_to_mid_ratio >= 2:
        report.boundary_crisis_severity = "MODERATE"
    elif report.boundary_to_mid_ratio >= 1.5:
        report.boundary_crisis_severity = "MILD"
    else:
        report.boundary_crisis_severity = "NORMAL"

    return report, all_errors


def generate_heatmap_data(errors: List[ErrorInstance], bins: int = 20) -> List[Dict]:
    """
    ç”Ÿæˆçƒ­å›¾æ•°æ®

    Args:
        errors: é”™è¯¯å®ä¾‹åˆ—è¡¨
        bins: ä½ç½®åŒºé—´æ•°é‡

    Returns:
        çƒ­å›¾æ•°æ®åˆ—è¡¨
    """
    if not errors:
        return []

    # æŒ‰ä½ç½®åŒºé—´ç»Ÿè®¡
    bin_counts = defaultdict(lambda: {"total": 0, "delete": 0, "insert": 0, "replace": 0})

    for error in errors:
        bin_idx = int(error.normalized_position * bins)
        bin_idx = min(bin_idx, bins - 1)  # ç¡®ä¿ä¸è¶Šç•Œ

        bin_counts[bin_idx]["total"] += 1
        bin_counts[bin_idx][error.error_type] += 1

    # è½¬æ¢ä¸ºåˆ—è¡¨
    heatmap_data = []
    for bin_idx in range(bins):
        bin_start = bin_idx / bins
        bin_end = (bin_idx + 1) / bins

        counts = bin_counts[bin_idx]
        heatmap_data.append(
            {
                "bin_index": bin_idx,
                "position_start": round(bin_start, 3),
                "position_end": round(bin_end, 3),
                "position_center": round((bin_start + bin_end) / 2, 3),
                "total_errors": counts["total"],
                "delete_errors": counts["delete"],
                "insert_errors": counts["insert"],
                "replace_errors": counts["replace"],
            }
        )

    return heatmap_data


def save_heatmap_csv(heatmap_data: List[Dict], output_path: Path):
    """ä¿å­˜çƒ­å›¾æ•°æ®ä¸º CSV"""
    if not heatmap_data:
        print("[WARNING] æ— çƒ­å›¾æ•°æ®å¯ä¿å­˜")
        return

    output_path.parent.mkdir(parents=True, exist_ok=True)

    with open(output_path, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=heatmap_data[0].keys())
        writer.writeheader()
        writer.writerows(heatmap_data)

    print(f"[INFO] çƒ­å›¾æ•°æ®å·²ä¿å­˜: {output_path}")


def save_report_json(report: AnalysisReport, output_path: Path):
    """ä¿å­˜åˆ†ææŠ¥å‘Šä¸º JSON"""
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # è½¬æ¢ä¸ºå­—å…¸
    report_dict = {
        "summary": {
            "total_samples": report.total_samples,
            "valid_samples": report.valid_samples,
            "skipped_samples": report.skipped_samples,
            "overall_cer": round(report.overall_cer, 4),
            "overall_avg_confidence": round(report.overall_avg_confidence, 4),
        },
        "segment_analysis": {
            "boundary_left": {
                "total_chars": report.boundary_left_stats.total_chars,
                "error_chars": report.boundary_left_stats.error_chars,
                "cer": round(report.boundary_left_stats.cer, 4),
                "delete_count": report.boundary_left_stats.delete_count,
                "insert_count": report.boundary_left_stats.insert_count,
                "replace_count": report.boundary_left_stats.replace_count,
            },
            "boundary_right": {
                "total_chars": report.boundary_right_stats.total_chars,
                "error_chars": report.boundary_right_stats.error_chars,
                "cer": round(report.boundary_right_stats.cer, 4),
                "delete_count": report.boundary_right_stats.delete_count,
                "insert_count": report.boundary_right_stats.insert_count,
                "replace_count": report.boundary_right_stats.replace_count,
            },
            "mid_section": {
                "total_chars": report.mid_section_stats.total_chars,
                "error_chars": report.mid_section_stats.error_chars,
                "cer": round(report.mid_section_stats.cer, 4),
                "delete_count": report.mid_section_stats.delete_count,
                "insert_count": report.mid_section_stats.insert_count,
                "replace_count": report.mid_section_stats.replace_count,
            },
        },
        "boundary_crisis_metrics": {
            "boundary_cer": round(report.boundary_cer, 4),
            "mid_cer": round(report.mid_cer, 4),
            "boundary_to_mid_ratio": round(report.boundary_to_mid_ratio, 2),
            "edge_10_percent_error_ratio": round(report.edge_10_percent_error_ratio, 4),
            "edge_20_percent_error_ratio": round(report.edge_20_percent_error_ratio, 4),
        },
        "error_type_distribution": {
            "total_errors": report.total_errors,
            "delete_errors": report.delete_errors,
            "delete_ratio": round(report.delete_errors / max(1, report.total_errors), 4),
            "insert_errors": report.insert_errors,
            "insert_ratio": round(report.insert_errors / max(1, report.total_errors), 4),
            "replace_errors": report.replace_errors,
            "replace_ratio": round(report.replace_errors / max(1, report.total_errors), 4),
        },
        "hypothesis_test": {
            "hypothesis": "CER_boundary > 3 Ã— CER_mid",
            "confirmed": report.hypothesis_confirmed,
            "boundary_crisis_severity": report.boundary_crisis_severity,
        },
        "paper_ready_stats": {
            "è¾¹ç•ŒåŒºåŸŸCER": f"{report.boundary_cer * 100:.2f}%",
            "ä¸­é—´åŒºåŸŸCER": f"{report.mid_cer * 100:.2f}%",
            "è¾¹ç•Œ/ä¸­é—´æ¯”å€¼": f"{report.boundary_to_mid_ratio:.2f}x",
            "è¾¹ç¼˜10%é”™è¯¯å æ¯”": f"{report.edge_10_percent_error_ratio * 100:.1f}%",
            "åˆ é™¤é”™è¯¯å æ¯”": f"{report.delete_errors / max(1, report.total_errors) * 100:.1f}%",
        },
    }

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(report_dict, f, ensure_ascii=False, indent=2)

    print(f"[INFO] åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {output_path}")


def generate_visualization(
    report: AnalysisReport,
    heatmap_data: List[Dict],
    errors: List[ErrorInstance],
    output_path: Path,
):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    if not HAS_MATPLOTLIB:
        print("[INFO] matplotlib æœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")
        return

    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # 1. åˆ†æ®µ CER å¯¹æ¯”
    ax1 = axes[0, 0]
    segments = ["Boundary\nLeft", "Mid\nSection", "Boundary\nRight"]
    cers = [
        report.boundary_left_stats.cer,
        report.mid_section_stats.cer,
        report.boundary_right_stats.cer,
    ]
    colors = ["#e74c3c", "#27ae60", "#e74c3c"]
    bars = ax1.bar(segments, cers, color=colors, alpha=0.8, edgecolor="black")
    ax1.set_ylabel("CER", fontsize=12)
    ax1.set_title("Segment-wise CER Comparison", fontsize=14, fontweight="bold")
    ax1.set_ylim([0, max(cers) * 1.3 if cers else 1])

    # æ·»åŠ æ•°å€¼æ ‡æ³¨
    for bar, cer in zip(bars, cers):
        ax1.text(
            bar.get_x() + bar.get_width() / 2,
            bar.get_height() + 0.01,
            f"{cer:.2%}",
            ha="center",
            va="bottom",
            fontsize=10,
            fontweight="bold",
        )

    # 2. é”™è¯¯ä½ç½®åˆ†å¸ƒçƒ­å›¾
    ax2 = axes[0, 1]
    if heatmap_data:
        positions = [d["position_center"] for d in heatmap_data]
        counts = [d["total_errors"] for d in heatmap_data]
        ax2.bar(
            positions,
            counts,
            width=1 / len(heatmap_data),
            color="#3498db",
            alpha=0.7,
            edgecolor="black",
        )
        ax2.set_xlabel("Normalized Position (0=Left, 1=Right)", fontsize=12)
        ax2.set_ylabel("Error Count", fontsize=12)
        ax2.set_title(
            "Error Distribution by Position\n(Boundary Crisis Visualization)",
            fontsize=14,
            fontweight="bold",
        )
        ax2.axvspan(0, 0.1, alpha=0.3, color="red", label="Edge 10%")
        ax2.axvspan(0.9, 1.0, alpha=0.3, color="red")
        ax2.legend(loc="upper right")

    # 3. é”™è¯¯ç±»å‹åˆ†å¸ƒ
    ax3 = axes[1, 0]
    error_types = ["Deletion", "Substitution", "Insertion"]
    error_counts = [report.delete_errors, report.replace_errors, report.insert_errors]
    colors = ["#e74c3c", "#f39c12", "#9b59b6"]
    wedges, texts, autotexts = ax3.pie(
        error_counts,
        labels=error_types,
        colors=colors,
        autopct="%1.1f%%",
        startangle=90,
        explode=(0.05, 0, 0),
    )
    ax3.set_title("Error Type Distribution", fontsize=14, fontweight="bold")

    # 4. è®ºæ–‡çº§ç»Ÿè®¡æ‘˜è¦
    ax4 = axes[1, 1]
    ax4.axis("off")

    summary_text = f"""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘         BOUNDARY CRISIS ANALYSIS REPORT          â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘                                                  â•‘
    â•‘  Total Samples: {report.valid_samples:,}                            
    â•‘  Overall CER: {report.overall_cer:.2%}                           
    â•‘                                                  â•‘
    â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SEGMENT CER â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â•‘
    â•‘  Boundary (Left + Right): {report.boundary_cer:.2%}              
    â•‘  Middle Section: {report.mid_cer:.2%}                       
    â•‘  Boundary/Mid Ratio: {report.boundary_to_mid_ratio:.2f}x                     
    â•‘                                                  â•‘
    â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ EDGE ANALYSIS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â•‘
    â•‘  Edge 10% Error Ratio: {report.edge_10_percent_error_ratio:.1%}                  
    â•‘  Edge 20% Error Ratio: {report.edge_20_percent_error_ratio:.1%}                  
    â•‘                                                  â•‘
    â•‘  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HYPOTHESIS TEST â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â•‘
    â•‘  Hâ‚€: CER_boundary > 3 Ã— CER_mid                 â•‘
    â•‘  Result: {'âœ“ CONFIRMED' if report.hypothesis_confirmed else 'âœ— NOT CONFIRMED'}                           
    â•‘  Severity: {report.boundary_crisis_severity}                             
    â•‘                                                  â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """

    ax4.text(
        0.5,
        0.5,
        summary_text,
        transform=ax4.transAxes,
        fontsize=10,
        verticalalignment="center",
        horizontalalignment="center",
        fontfamily="monospace",
        bbox=dict(boxstyle="round", facecolor="wheat", alpha=0.5),
    )

    plt.tight_layout()
    output_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches="tight", facecolor="white")
    plt.close()

    print(f"[INFO] å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {output_path}")


def print_summary(report: AnalysisReport):
    """æ‰“å°åˆ†ææ‘˜è¦"""
    print("\n" + "=" * 70)
    print("L2W1 è¾¹ç•Œå¤±è´¥åˆ†ææŠ¥å‘Š")
    print("=" * 70)

    print(f"\nğŸ“Š åŸºç¡€ç»Ÿè®¡:")
    print(f"   æ€»æ ·æœ¬æ•°: {report.total_samples}")
    print(f"   æœ‰æ•ˆæ ·æœ¬: {report.valid_samples}")
    print(f"   è·³è¿‡æ ·æœ¬: {report.skipped_samples}")
    print(f"   æ•´ä½“ CER: {report.overall_cer:.2%}")
    print(f"   å¹³å‡ç½®ä¿¡åº¦: {report.overall_avg_confidence:.4f}")

    print(f"\nğŸ“ åˆ†æ®µ CER åˆ†æ:")
    print(f"   è¾¹ç•Œå·¦ä¾§ (é¦–2å­—ç¬¦): {report.boundary_left_stats.cer:.2%}")
    print(f"   ä¸­é—´åŒºåŸŸ: {report.mid_section_stats.cer:.2%}")
    print(f"   è¾¹ç•Œå³ä¾§ (å°¾2å­—ç¬¦): {report.boundary_right_stats.cer:.2%}")

    print(f"\nğŸ”¥ è¾¹ç•Œå±æœºæŒ‡æ ‡:")
    print(f"   è¾¹ç•ŒåŒºåŸŸ CER: {report.boundary_cer:.2%}")
    print(f"   ä¸­é—´åŒºåŸŸ CER: {report.mid_cer:.2%}")
    print(f"   è¾¹ç•Œ/ä¸­é—´æ¯”å€¼: {report.boundary_to_mid_ratio:.2f}x")
    print(f"   è¾¹ç¼˜ 10% é”™è¯¯å æ¯”: {report.edge_10_percent_error_ratio:.1%}")
    print(f"   è¾¹ç¼˜ 20% é”™è¯¯å æ¯”: {report.edge_20_percent_error_ratio:.1%}")

    print(f"\nâŒ é”™è¯¯ç±»å‹åˆ†å¸ƒ:")
    print(f"   æ€»é”™è¯¯æ•°: {report.total_errors}")
    print(
        f"   åˆ é™¤é”™è¯¯: {report.delete_errors} ({report.delete_errors/max(1,report.total_errors):.1%})"
    )
    print(
        f"   æ›¿æ¢é”™è¯¯: {report.replace_errors} ({report.replace_errors/max(1,report.total_errors):.1%})"
    )
    print(
        f"   æ’å…¥é”™è¯¯: {report.insert_errors} ({report.insert_errors/max(1,report.total_errors):.1%})"
    )

    print(f"\nğŸ“‹ å‡è®¾éªŒè¯:")
    print(f"   å‡è®¾: CER_boundary > 3 Ã— CER_mid")
    print(f"   ç»“æœ: {'âœ“ å‡è®¾æˆç«‹' if report.hypothesis_confirmed else 'âœ— å‡è®¾ä¸æˆç«‹'}")
    print(f"   å±æœºä¸¥é‡ç¨‹åº¦: {report.boundary_crisis_severity}")

    # è®ºæ–‡ç»“è®º
    print(f"\n" + "=" * 70)
    print("ğŸ“ è®ºæ–‡å¯å¼•ç”¨ç»“è®º:")
    print("=" * 70)
    if report.hypothesis_confirmed:
        print(
            f"""
æˆ‘ä»¬çš„å®éªŒè¡¨æ˜ï¼ŒPP-OCRv5 åœ¨ HWDB æ•°æ®é›†ä¸Šå­˜åœ¨æ˜¾è‘—çš„"è¾¹ç•Œæ„ŸçŸ¥åå¡Œ"ç°è±¡ï¼š
â€¢ è¾¹ç•ŒåŒºåŸŸï¼ˆé¦–å°¾å„ 2 å­—ç¬¦ï¼‰çš„ CER ä¸º {report.boundary_cer:.2%}ï¼Œ
  æ˜¯ä¸­é—´åŒºåŸŸ ({report.mid_cer:.2%}) çš„ {report.boundary_to_mid_ratio:.1f} å€ã€‚
â€¢ è¾¹ç¼˜ 10% åŒºåŸŸè´¡çŒ®äº† {report.edge_10_percent_error_ratio:.0%} çš„æ€»é”™è¯¯ã€‚
â€¢ åˆ é™¤é”™è¯¯ï¼ˆå­—ç¬¦ä¸¢å¤±ï¼‰å æ¯” {report.delete_errors/max(1,report.total_errors):.0%}ï¼Œ
  è¡¨æ˜æ¨¡å‹å€¾å‘äº"å¿½ç•¥"è¾¹ç•Œå­—ç¬¦è€Œé"è¯¯è¯†åˆ«"ã€‚
è¿™ä¸€å‘ç°éªŒè¯äº†æˆ‘ä»¬æå‡ºçš„è¾¹ç•Œæ•æ„Ÿè·¯ç”±ç­–ç•¥çš„å¿…è¦æ€§ã€‚
"""
        )
    else:
        print(
            f"""
è¾¹ç•Œåˆ†æç»“æœæ˜¾ç¤ºï¼Œå½“å‰æ•°æ®é›†çš„è¾¹ç•Œæ•ˆåº”ä¸æ˜¾è‘—ï¼š
â€¢ è¾¹ç•ŒåŒºåŸŸ CER: {report.boundary_cer:.2%}
â€¢ ä¸­é—´åŒºåŸŸ CER: {report.mid_cer:.2%}
â€¢ æ¯”å€¼: {report.boundary_to_mid_ratio:.2f}x (æœªè¾¾åˆ° 3x é˜ˆå€¼)
å»ºè®®è¿›ä¸€æ­¥æ£€æŸ¥æ•°æ®è´¨é‡æˆ–è°ƒæ•´åˆ†æå‚æ•°ã€‚
"""
        )

    print("=" * 70)


def main():
    parser = argparse.ArgumentParser(
        description="L2W1 è¾¹ç•Œå¤±è´¥æ·±åº¦åˆ†æ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        "--input",
        type=str,
        default="results/baseline_results.jsonl",
        help="è¾“å…¥ JSONL æ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--output_report",
        type=str,
        default="results/boundary_analysis_report.json",
        help="è¾“å‡ºæŠ¥å‘Šè·¯å¾„",
    )
    parser.add_argument(
        "--output_heatmap",
        type=str,
        default="results/error_heatmap_data.csv",
        help="è¾“å‡ºçƒ­å›¾æ•°æ®è·¯å¾„",
    )
    parser.add_argument(
        "--output_chart",
        type=str,
        default="results/boundary_analysis.png",
        help="è¾“å‡ºå¯è§†åŒ–å›¾è¡¨è·¯å¾„",
    )
    parser.add_argument(
        "--boundary_window",
        type=int,
        default=2,
        help="è¾¹ç•Œçª—å£å¤§å° (é¦–å°¾å„å¤šå°‘å­—ç¬¦)",
    )
    parser.add_argument(
        "--heatmap_bins",
        type=int,
        default=20,
        help="çƒ­å›¾ä½ç½®åŒºé—´æ•°é‡",
    )

    args = parser.parse_args()

    print("=" * 70)
    print("L2W1 è¾¹ç•Œå¤±è´¥æ·±åº¦åˆ†æè„šæœ¬")
    print("=" * 70)
    print(f"è¾“å…¥æ–‡ä»¶: {args.input}")
    print(f"è¾¹ç•Œçª—å£: é¦–å°¾å„ {args.boundary_window} å­—ç¬¦")
    print()

    # åŠ è½½æ•°æ®
    input_path = Path(args.input)
    samples = load_baseline_results(input_path)

    if not samples:
        print("[ERROR] æœªåŠ è½½åˆ°æœ‰æ•ˆæ ·æœ¬")
        sys.exit(1)

    # æ‰§è¡Œåˆ†æ
    print("[INFO] æ­£åœ¨åˆ†æé”™è¯¯åˆ†å¸ƒ...")
    report, errors = run_analysis(samples, args.boundary_window)

    # ç”Ÿæˆçƒ­å›¾æ•°æ®
    print("[INFO] ç”Ÿæˆçƒ­å›¾æ•°æ®...")
    heatmap_data = generate_heatmap_data(errors, args.heatmap_bins)

    # ä¿å­˜ç»“æœ
    save_report_json(report, Path(args.output_report))
    save_heatmap_csv(heatmap_data, Path(args.output_heatmap))

    # ç”Ÿæˆå¯è§†åŒ–
    generate_visualization(report, heatmap_data, errors, Path(args.output_chart))

    # æ‰“å°æ‘˜è¦
    print_summary(report)


if __name__ == "__main__":
    main()

