# L2W1 v5.0 ç¯å¢ƒå®‰è£…æŒ‡å—

**éƒ¨ç½²ç¯å¢ƒ**: Linux Server (Ubuntu 20.04+)  
**GPU**: NVIDIA RTX 2080Ti (22GB æ˜¾å­˜)  
**CUDA**: 11.8  
**Python**: 3.9-3.11 (æ¨è 3.10)

---

## ğŸ“‹ å‰ç½®æ¡ä»¶

### 1. ç³»ç»Ÿè¦æ±‚

```bash
# æ£€æŸ¥ç³»ç»Ÿç‰ˆæœ¬
cat /etc/os-release

# æ£€æŸ¥ GPU
nvidia-smi

# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version
# æˆ–
cat /usr/local/cuda/version.txt
```

### 2. NVIDIA é©±åŠ¨å’Œ CUDA

**RTX 2080Ti è¦æ±‚**:

- NVIDIA Driver: >= 450.80.02
- CUDA: 11.8 (æ¨è) æˆ– 11.7
- cuDNN: 8.2+ (ç”¨äº PaddlePaddle)

**å®‰è£… CUDA 11.8** (å¦‚æœæœªå®‰è£…):

```bash
# ä¸‹è½½ CUDA 11.8
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run

# å®‰è£…
sudo sh cuda_11.8.0_520.61.05_linux.run

# é…ç½®ç¯å¢ƒå˜é‡ (æ·»åŠ åˆ° ~/.bashrc)
export PATH=/usr/local/cuda-11.8/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH

# é‡æ–°åŠ è½½
source ~/.bashrc
```

---

## ğŸ Python ç¯å¢ƒ

### æ–¹æ³• 1: ä½¿ç”¨ Conda (æ¨è)

```bash
# åˆ›å»º conda ç¯å¢ƒ
conda create -n l2w1 python=3.10 -y
conda activate l2w1

# å®‰è£… PyTorch (CUDA 11.8)
conda install pytorch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 pytorch-cuda=11.8 -c pytorch -c nvidia -y

# éªŒè¯ PyTorch
python -c "import torch; print(torch.__version__); print(torch.cuda.is_available()); print(torch.version.cuda)"
```

### æ–¹æ³• 2: ä½¿ç”¨ venv

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.10 -m venv venv
source venv/bin/activate

# å‡çº§ pip
pip install --upgrade pip setuptools wheel
```

---

## ğŸ“¦ å®‰è£…ä¾èµ–

### æ­¥éª¤ 1: å®‰è£… PyTorch (å¦‚æœä½¿ç”¨ venv)

```bash
# CUDA 11.8 ç‰ˆæœ¬
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118

# éªŒè¯
python -c "import torch; print(torch.cuda.is_available())"
```

### æ­¥éª¤ 2: å®‰è£… PaddlePaddle

```bash
# GPU ç‰ˆæœ¬ (CUDA 11.2+)
python -m pip install paddlepaddle-gpu==2.6.1 -i https://mirror.baidu.com/pypi/simple

# éªŒè¯
python -c "import paddle; paddle.utils.run_check()"
```

**æ³¨æ„**:

- å¦‚æœå®‰è£…å¤±è´¥ï¼Œæ£€æŸ¥ CUDA å’Œ cuDNN ç‰ˆæœ¬
- PaddlePaddle éœ€è¦ cuDNN 8.2+ï¼Œå¯ä»¥é€šè¿‡ `conda install cudnn -c conda-forge` å®‰è£…

### æ­¥éª¤ 3: å®‰è£…å…¶ä»–ä¾èµ–

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd L2W1

# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å¦‚æœéœ€è¦å¼€å‘å·¥å…·
pip install -r requirements-dev.txt
```

### æ­¥éª¤ 4: å®‰è£… BitsAndBytes (4-bit é‡åŒ–)

```bash
# æ–¹æ³• 1: ç›´æ¥å®‰è£… (è‡ªåŠ¨æ£€æµ‹ CUDA)
pip install bitsandbytes

# æ–¹æ³• 2: å¦‚æœå¤±è´¥ï¼Œä»æºç ç¼–è¯‘
# git clone https://github.com/TimDettmers/bitsandbytes.git
# cd bitsandbytes
# CUDA_VERSION=118 make cuda11x
# python setup.py install
```

**éªŒè¯**:

```python
python -c "import bitsandbytes as bnb; print('BitsAndBytes installed successfully')"
```

### æ­¥éª¤ 5: å®‰è£… Flash Attention 2 (å¯é€‰ä½†æ¨è)

```bash
# æ–¹æ³• 1: ç›´æ¥å®‰è£… (éœ€è¦ CUDA ç¼–è¯‘å™¨)
pip install flash-attn --no-build-isolation

# æ–¹æ³• 2: å¦‚æœå¤±è´¥ï¼Œä»æºç ç¼–è¯‘
# pip install flash-attn==2.5.0
```

**æ³¨æ„**: Flash Attention 2 éœ€è¦ç¼–è¯‘ï¼Œç¡®ä¿å·²å®‰è£… `ninja`:

```bash
pip install ninja
```

---

## âœ… éªŒè¯å®‰è£…

### 1. æ£€æŸ¥æ ¸å¿ƒåº“

```bash
cd L2W1

python -c "
import torch
import paddle
import transformers
import peft
import bitsandbytes as bnb
import numpy as np
import cv2
from PIL import Image

print('=' * 60)
print('L2W1 ç¯å¢ƒéªŒè¯')
print('=' * 60)
print(f'PyTorch: {torch.__version__}')
print(f'CUDA Available: {torch.cuda.is_available()}')
print(f'CUDA Version: {torch.version.cuda}')
print(f'GPU Count: {torch.cuda.device_count()}')
if torch.cuda.is_available():
    print(f'GPU Name: {torch.cuda.get_device_name(0)}')
print(f'PaddlePaddle: {paddle.__version__}')
print(f'Transformers: {transformers.__version__}')
print(f'PEFT: {peft.__version__}')
print(f'BitsAndBytes: {bnb.__version__}')
print(f'NumPy: {np.__version__}')
print(f'OpenCV: {cv2.__version__}')
print('=' * 60)
print('âœ… æ‰€æœ‰æ ¸å¿ƒåº“å®‰è£…æˆåŠŸ!')
print('=' * 60)
"
```

### 2. æµ‹è¯• GPU æ˜¾å­˜

```python
python -c "
import torch
if torch.cuda.is_available():
    device = torch.device('cuda:0')
    # åˆ†é… 1GB æ˜¾å­˜æµ‹è¯•
    x = torch.randn(1024, 1024, 256).to(device)
    print(f'âœ… GPU å¯ç”¨ï¼Œå·²åˆ†é… {x.element_size() * x.nelement() / 1024**3:.2f} GB æ˜¾å­˜')
    del x
    torch.cuda.empty_cache()
    print(f'âœ… æ˜¾å­˜å·²é‡Šæ”¾ï¼Œå½“å‰ä½¿ç”¨: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB')
else:
    print('âŒ GPU ä¸å¯ç”¨')
"
```

### 3. æµ‹è¯• PaddleOCR é›†æˆ

```python
python -c "
import sys
from pathlib import Path
sys.path.insert(0, str(Path('.').absolute().parent))

from L2W1.modules.paddle_engine import TextRecognizerWithLogits

print('æµ‹è¯• PaddleOCR é›†æˆ...')
# è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„æµ‹è¯•ä»£ç 
print('âœ… PaddleOCR æ¨¡å—å¯¼å…¥æˆåŠŸ')
"
```

---

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: BitsAndBytes å®‰è£…å¤±è´¥

**åŸå› **: CUDA ç‰ˆæœ¬ä¸åŒ¹é…æˆ–ç¼ºå°‘ç¼–è¯‘å·¥å…·

**è§£å†³æ–¹æ¡ˆ**:

```bash
# å®‰è£…ç¼–è¯‘å·¥å…·
sudo apt-get update
sudo apt-get install build-essential

# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc --version

# é‡æ–°å®‰è£…
pip install bitsandbytes --no-cache-dir
```

### Q2: Flash Attention 2 å®‰è£…å¤±è´¥

**åŸå› **: éœ€è¦ç¼–è¯‘ï¼ŒCUDA ç‰ˆæœ¬ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ 1: è·³è¿‡ Flash Attention (ä¼šä½¿ç”¨æ™®é€š attention)
# åœ¨ä»£ç ä¸­è®¾ç½® use_flash_attention=False

# æ–¹æ¡ˆ 2: å®‰è£…ç¼–è¯‘ä¾èµ–
pip install ninja packaging wheel
pip install flash-attn --no-build-isolation
```

### Q3: PaddlePaddle æ— æ³•æ£€æµ‹ GPU

**åŸå› **: CUDA/cuDNN ç‰ˆæœ¬ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ£€æŸ¥ PaddlePaddle å®‰è£…
python -c "import paddle; paddle.utils.run_check()"

# å¦‚æœå¤±è´¥ï¼Œé‡æ–°å®‰è£…åŒ¹é…çš„ç‰ˆæœ¬
pip uninstall paddlepaddle-gpu
pip install paddlepaddle-gpu==2.6.1.post118 -f https://www.paddlepaddle.org.cn/whl/linux/mkl/avx/stable.html
```

### Q4: æ˜¾å­˜ä¸è¶³ (OOM)

**RTX 2080Ti å®é™…æ˜¾å­˜ä¸º 11GB**ï¼Œå¦‚æœé‡åˆ° OOM:

1. ç¡®ä¿ä½¿ç”¨ 4-bit é‡åŒ–:

   ```python
   use_4bit=True  # Agent B é…ç½®
   ```

2. å‡å° batch size:

   ```python
   batch_size=2  # è®­ç»ƒæ—¶
   ```

3. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹:
   ```python
   gradient_checkpointing=True
   ```

### Q5: ç‰ˆæœ¬å†²çª

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒéš”ç¦»

```bash
# é‡æ–°åˆ›å»ºå¹²å‡€ç¯å¢ƒ
conda create -n l2w1_clean python=3.10 -y
conda activate l2w1_clean

# æŒ‰é¡ºåºå®‰è£…
pip install torch==2.1.2 torchvision==0.16.2 --index-url https://download.pytorch.org/whl/cu118
pip install paddlepaddle-gpu==2.6.1 -i https://mirror.baidu.com/pypi/simple
pip install -r requirements.txt
```

---

## ğŸ“ VS Code é…ç½®

### 1. Python è§£é‡Šå™¨

åœ¨ VS Code ä¸­:

1. æŒ‰ `Ctrl+Shift+P`
2. è¾“å…¥ "Python: Select Interpreter"
3. é€‰æ‹©åˆ›å»ºçš„è™šæ‹Ÿç¯å¢ƒ: `./venv/bin/python` æˆ– `~/anaconda3/envs/l2w1/bin/python`

### 2. æ¨èæ‰©å±•

- Python (Microsoft)
- Pylance (Microsoft)
- Jupyter (Microsoft)
- Python Docstring Generator

### 3. å·¥ä½œåŒºè®¾ç½®

åˆ›å»º `.vscode/settings.json`:

```json
{
  "python.defaultInterpreterPath": "${workspaceFolder}/venv/bin/python",
  "python.linting.enabled": true,
  "python.linting.pylintEnabled": true,
  "python.formatting.provider": "black",
  "editor.formatOnSave": true,
  "python.analysis.typeCheckingMode": "basic"
}
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

```bash
# 1. æ¿€æ´»ç¯å¢ƒ
conda activate l2w1  # æˆ– source venv/bin/activate

# 2. è¿è¡Œæ•°æ®ç®¡é“
python scripts/data_pipeline.py --data_dir ./data/raw --output_dir ./data/sft

# 3. è®­ç»ƒ Agent B
python scripts/train_agent_b.py --data_path ./data/sft/agent_b_train.jsonl

# 4. è¯„ä¼°
python scripts/evaluate.py --predictions ./data/test/inference_results.jsonl
```

---

**å®‰è£…å®Œæˆ!** ğŸ‰

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ `CODE_AUDIT_REPORT.md` æˆ–æäº¤ Issueã€‚
